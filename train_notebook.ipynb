{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune a Hugging Face Text Classification Model\n",
    "\n",
    "This notebook mirrors the functionality of `train.py` and walks through the steps required\n",
    "to fine-tune a Hugging Face text classification model on a JSONL dataset containing\n",
    "`text` and `labels` fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import evaluate\n",
    "from datasets import DatasetDict, load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ScriptArguments:\n",
    "    \"\"\"Configuration settings used throughout the fine-tuning workflow.\"\"\"\n",
    "\n",
    "    model_name_or_path: str\n",
    "    train_file: Path\n",
    "    validation_file: Optional[Path]\n",
    "    output_dir: Path\n",
    "    max_length: int = 512\n",
    "    learning_rate: float = 5e-5\n",
    "    per_device_train_batch_size: int = 8\n",
    "    per_device_eval_batch_size: int = 8\n",
    "    num_train_epochs: int = 3\n",
    "    weight_decay: float = 0.0\n",
    "    warmup_ratio: float = 0.0\n",
    "    logging_steps: int = 50\n",
    "    eval_steps: Optional[int] = None\n",
    "    seed: int = 42\n",
    "\n",
    "\n",
    "def load_json_dataset(train_path: Path, validation_path: Optional[Path]) -> DatasetDict:\n",
    "    data_files = {\"train\": str(train_path)}\n",
    "    if validation_path is not None:\n",
    "        data_files[\"validation\"] = str(validation_path)\n",
    "\n",
    "    dataset = load_dataset(\"json\", data_files=data_files)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def prepare_label_mapping(dataset: DatasetDict) -> tuple[DatasetDict, dict[int, str], dict[str, int]]:\n",
    "    \"\"\"Ensure labels are consecutive integers and return mapping dictionaries.\"\"\"\n",
    "\n",
    "    unique_labels = sorted(set(dataset[\"train\"][\"labels\"]))\n",
    "    id2label = {idx: str(label) for idx, label in enumerate(unique_labels)}\n",
    "    label2id = {label: idx for idx, label in id2label.items()}\n",
    "\n",
    "    def _map_labels(example):\n",
    "        example[\"labels\"] = label2id[str(example[\"labels\"])]\n",
    "        return example\n",
    "\n",
    "    dataset = dataset.map(_map_labels)\n",
    "    return dataset, id2label, label2id\n",
    "\n",
    "\n",
    "def tokenize_dataset(dataset: DatasetDict, tokenizer: AutoTokenizer, max_length: int) -> DatasetDict:\n",
    "    def preprocess_function(examples):\n",
    "        tokenized = tokenizer(\n",
    "            examples[\"text\"],\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        tokenized[\"labels\"] = examples[\"labels\"]\n",
    "        return tokenized\n",
    "\n",
    "    return dataset.map(preprocess_function, batched=True, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the run\n",
    "\n",
    "Populate the paths and hyperparameters you want to use for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ScriptArguments(\n",
    "    model_name_or_path=\"bert-base-uncased\",\n",
    "    train_file=Path(\"path/to/train.jsonl\"),\n",
    "    validation_file=Path(\"path/to/valid.jsonl\"),\n",
    "    output_dir=Path(\"./model-output\"),\n",
    "    max_length=512,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.0,\n",
    "    warmup_ratio=0.0,\n",
    "    logging_steps=50,\n",
    "    eval_steps=None,\n",
    "    seed=42,\n",
    ")\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Loading dataset...\")\n",
    "raw_dataset = load_json_dataset(args.train_file, args.validation_file)\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "processed_dataset, id2label, label2id = prepare_label_mapping(raw_dataset)\n",
    "num_labels = len(id2label)\n",
    "tokenized_dataset = tokenize_dataset(processed_dataset, tokenizer, args.max_length)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = predictions.argmax(axis=-1)\n",
    "    return accuracy.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model, trainer, and start fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    args.model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "has_validation = args.validation_file is not None\n",
    "evaluation_strategy = \"steps\" if (has_validation and args.eval_steps) else (\"epoch\" if has_validation else \"no\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(args.output_dir),\n",
    "    learning_rate=args.learning_rate,\n",
    "    per_device_train_batch_size=args.per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=args.per_device_eval_batch_size,\n",
    "    num_train_epochs=args.num_train_epochs,\n",
    "    weight_decay=args.weight_decay,\n",
    "    warmup_ratio=args.warmup_ratio,\n",
    "    logging_steps=args.logging_steps,\n",
    "    evaluation_strategy=evaluation_strategy,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_steps=args.eval_steps if has_validation else None,\n",
    "    load_best_model_at_end=has_validation,\n",
    "    metric_for_best_model=\"accuracy\" if has_validation else None,\n",
    "    seed=args.seed,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset.get(\"validation\"),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(args.output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
